{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, scorer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import joblib\n",
    "from joblib import dump, load\n",
    "import hypopt\n",
    "from hypopt import GridSearch\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from keras import backend as K\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.read_pickle(\"X_all.pkl\")\n",
    "Y_all = pd.read_pickle(\"Y_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "[[ 13 213]\n",
      " [  6 206]]\n",
      "\n",
      "\n",
      "Iteration  1\n",
      "[[  3 179]\n",
      " [ 13 194]]\n",
      "\n",
      "\n",
      "Iteration  2\n",
      "[[  7 162]\n",
      " [ 11 196]]\n",
      "\n",
      "\n",
      "Iteration  3\n",
      "[[  7 167]\n",
      " [  6 196]]\n",
      "\n",
      "\n",
      "Iteration  4\n",
      "[[  8 220]\n",
      " [ 17 220]]\n",
      "\n",
      "\n",
      "Iteration  5\n",
      "[[ 11 155]\n",
      " [ 14 172]]\n",
      "\n",
      "\n",
      "Iteration  6\n",
      "[[  4 181]\n",
      " [  6 236]]\n",
      "\n",
      "\n",
      "Iteration  7\n",
      "[[  8 147]\n",
      " [  0 222]]\n",
      "\n",
      "\n",
      "Iteration  8\n",
      "[[ 13 155]\n",
      " [ 15 161]]\n",
      "\n",
      "\n",
      "Iteration  9\n",
      "[[ 11 165]\n",
      " [  6 191]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "final_cm=np.array([[0, 0],[0, 0]])\n",
    "\n",
    "dataset_covid_healthy = pd.read_pickle(\"dataset_covid_healthy.pkl\")\n",
    "uuids_status_unique= dataset_covid_healthy.filter(items=['uuid','status']).drop_duplicates()\n",
    "uuids = np.array(uuids_status_unique['uuid'])\n",
    "y_uuids = np.array(uuids_status_unique['status'])\n",
    "\n",
    "\n",
    "for index, (train, test) in enumerate(skf.split(uuids, y_uuids)):\n",
    "    print('Iteration ', index)\n",
    "    train_val = set(train)\n",
    "    val= list(random.sample(train_val, 234))\n",
    "    train = list(train_val - set(val))\n",
    "\n",
    "    train_uuids = uuids[train]\n",
    "    val_uuids = uuids[val]\n",
    "    test_uuids = uuids[test]\n",
    "    \n",
    "    # Creating folds and validation set for tuning\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for x in dataset_covid_healthy.iterrows():\n",
    "        if x[1]['uuid'] in train_uuids:\n",
    "            if x[1]['status']=='healthy':\n",
    "                X_train.append(X_all.loc[x[0]])\n",
    "                y_train.append(-1)\n",
    "        elif x[1]['uuid'] in test_uuids:\n",
    "            X_test.append(X_all.loc[x[0]])\n",
    "            y_test.append(1 if x[1]['status']=='healthy' else -1)\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    estimator = LocalOutlierFactor(novelty=True)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    preds = estimator.predict(X_test)\n",
    "    final_cm += confusion_matrix(y_test, preds)\n",
    "    \n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
